{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from lstm_model import RNN_LoadForecastser\n",
    "from lstm_model_2 import LoadForecastser\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e727cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "type_num = 10\n",
    "batch_size = 24\n",
    "n_features = 27\n",
    "n_hidden = 128\n",
    "seq_len = 96 * 7\n",
    "n_layers = 2\n",
    "out_features = 96\n",
    "do = 0.2\n",
    "lr = 0.0005\n",
    "wd = 0.01\n",
    "n_epochs = 150\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99309d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入要inverse transform的df数据,生成userID和coName的键值对\n",
    "csv_path = './data/type_%s_csv_after_anomaly_detection/' % type_num\n",
    "file_list = os.listdir(csv_path)\n",
    "user_id_df_dict = {}\n",
    "user_id_co_name_dict = {}\n",
    "for i in range(len(file_list)):\n",
    "    file = file_list[i]\n",
    "    coName, userID = file[:-4].split('_')\n",
    "    print(coName)\n",
    "    df = pd.read_csv(csv_path + file)\n",
    "    user_id_df_dict[userID] = df\n",
    "    user_id_co_name_dict[userID] = coName\n",
    "\n",
    "user_id_list = list(user_id_co_name_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d552b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "userID = user_id_list[k]\n",
    "coName = user_id_co_name_dict[userID]\n",
    "print(coName)\n",
    "user_df = user_id_df_dict[userID].copy()\n",
    "col_load = user_df.loc[:, 'load'].values.reshape(-1, 1)\n",
    "\n",
    "# 提取load的最大最小值\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(col_load)\n",
    "# del user_df\n",
    "# del col_load\n",
    "# del user_id_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99342ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ff90c3d0",
   "metadata": {},
   "source": [
    "# model = torch.load('./model.pkl')\n",
    "model = torch.load('./RMSE_56_days_365_8.pkl')\n",
    "model.eval()\n",
    "\n",
    "# 模型用于测试集\n",
    "test_x = test_x.to(device)\n",
    "test_y_pred = model(test_x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50038104",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 导入训练集和测试集\n",
    "\n",
    "npy_path = './output/train_test/type%s/%s_%s/' % (type_num, coName, userID)\n",
    "\n",
    "date_range = 365\n",
    "\n",
    "if date_range == 90:\n",
    "    test_x = np.load(npy_path + 'test_x_days_90.npy')\n",
    "    test_y = np.load(npy_path + 'test_y_days_90.npy')\n",
    "elif date_range == 365:\n",
    "    test_x = np.load(npy_path + 'test_x_days_365.npy')\n",
    "    test_y = np.load(npy_path + 'test_y_days_365.npy')\n",
    "\n",
    "\n",
    "\n",
    "# numpy to tensor\n",
    "test_x = torch.from_numpy(test_x).type(torch.Tensor)\n",
    "test_y = torch.from_numpy(test_y).type(torch.Tensor)\n",
    "\n",
    "model = LoadForecastser(n_features=n_features, n_hidden=n_hidden, seq_len=seq_len,\n",
    "                        n_layers=n_layers, out_features=out_features,\n",
    "                        do=do, device=device).to(device)\n",
    "path = '/home/gavin/Documents/GitHub/FedML/fedml_experiments/standalone/fedavg/'\n",
    "model.load_state_dict(torch.load(path + 'temp-20210428-030246.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 模型用于测试集\n",
    "test_x = test_x.to(device)\n",
    "test_y_pred = model(test_x).to(device)\n",
    "\n",
    "test_y_pred = test_y_pred.detach().cpu().numpy()\n",
    "\n",
    "print(test_x.shape)\n",
    "\n",
    "test_y = scaler.inverse_transform(test_y)\n",
    "print(test_y.shape)\n",
    "\n",
    "test_y_pred = scaler.inverse_transform(test_y_pred)\n",
    "print(test_y_pred.shape)\n",
    "\n",
    "testScore = math.sqrt(mean_squared_error(test_y[:, 0], test_y_pred[:, 0]))\n",
    "print('Test Score: %.2f RMSE' % testScore)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c000aaf5",
   "metadata": {},
   "source": [
    "y1 = test_y[-96: : 96, :]\n",
    "y1 = y1.reshape(y1.shape[0] * y1.shape[1])\n",
    "y2 = test_y_pred[-96: : 96, :]\n",
    "y2 = y2.reshape(y2.shape[0] * y2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family': 'Times New Roman',\n",
    "        'weight': 'normal',\n",
    "        'size': 20,\n",
    "       }\n",
    "CB91_Blue = '#2CBDFE'\n",
    "CB91_Green = '#47DBCD'\n",
    "CB91_Pink = '#F3A0F2'\n",
    "CB91_Purple = '#9D2EC5'\n",
    "CB91_Violet = '#661D98'\n",
    "CB91_Amber = '#F5B14C'\n",
    "color_list = [CB91_Blue, CB91_Pink, CB91_Green, CB91_Amber,\n",
    "              CB91_Purple, CB91_Violet]\n",
    "n_fig = 24\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(20, 60, forward=True)\n",
    "for i in range(n_fig):\n",
    "    j = 96 * i\n",
    "    ax = plt.subplot(n_fig, 1, i+1)\n",
    "    y1 = test_y[j: j+96: 96, :]\n",
    "    y1 = y1.reshape(y1.shape[0] * y1.shape[1])\n",
    "    y2 = test_y_pred[j: j+96: 96, :]\n",
    "    y2 = y2.reshape(y2.shape[0] * y2.shape[1])\n",
    "    x = range(0, y1.shape[0])\n",
    "    ax.plot(x, y1, color_list[0])\n",
    "    ax.plot(x, y2, color_list[-1])\n",
    "    plt.xticks(font=font)\n",
    "    plt.yticks(font=font)\n",
    "    ax.set_ylabel('values_day%s' % (i+1), font=font)\n",
    "    ax.set_xticks(np.arange(0, y1.shape[0], 96))\n",
    "    ax.set_xticklabels(np.arange(0, y1.shape[0]/96))\n",
    "\n",
    "path = './output/img/testing/type%s/' % type_num\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "plt.savefig(path + '/forward_per_day_%d_k_%d.jpg' % (int(testScore), k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91b992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "y1 = test_y[i::96, :]\n",
    "y1 = y1.reshape(y1.shape[0] * y1.shape[1])\n",
    "print(y1.shape)\n",
    "y2 = test_y_pred[i::96, :]\n",
    "y2 = y2.reshape(y2.shape[0] * y2.shape[1])\n",
    "print(y2.shape)\n",
    "\n",
    "font = {'family': 'Times New Roman',\n",
    "        'weight': 'normal',\n",
    "        'size': 20,\n",
    "       }\n",
    "CB91_Blue = '#2CBDFE'\n",
    "CB91_Green = '#47DBCD'\n",
    "CB91_Pink = '#F3A0F2'\n",
    "CB91_Purple = '#9D2EC5'\n",
    "CB91_Violet = '#661D98'\n",
    "CB91_Amber = '#F5B14C'\n",
    "color_list = [CB91_Blue, CB91_Pink, CB91_Green, CB91_Amber,\n",
    "              CB91_Purple, CB91_Violet]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50, 10))\n",
    "x = range(0, y1.shape[0])\n",
    "ax.plot(x, y1, color_list[0])\n",
    "ax.plot(x, y2, color_list[-1])\n",
    "plt.xticks(font=font)\n",
    "plt.yticks(font=font)\n",
    "ax.set_ylabel('values', font=font)\n",
    "ax.set_xticks(np.arange(0, y1.shape[0], 96))\n",
    "ax.set_xticklabels(np.arange(0, y1.shape[0]/96))\n",
    "plt.savefig('./output/img/forward_all_days_%d_k_%d.jpg' % (int(testScore), k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d29ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from daily_load_plotting import daily_load_plotting\n",
    "import os\n",
    "import shutil\n",
    "from data_preprocessing.utils import find_files\n",
    "import pandas as pd\n",
    "\n",
    "from tsmoothie.smoother import *\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc00cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing(df):\n",
    "    data = df['load']\n",
    "#     smoother = KalmanSmoother(component='level_longseason',\n",
    "#                               component_noise={'level': 0.1, 'longseason': 0.1},\n",
    "#                               n_longseasons=365)\n",
    "#     data = smoother.smooth(data)\n",
    "    b, a = signal.butter(8, 0.8, 'lowpass')   #配置滤波器 8 表示滤波器的阶数\n",
    "    data = signal.filtfilt(b, a, data)  #data为要过滤的信号\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d515bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_detection(base_path, type_num, anomaly_detection_path, sum_flag=False, need_ad=True):\n",
    "    type_num_original_path = base_path + 'data/type_%s/original/' % type_num\n",
    "    type_num_after_anomaly_detection_path = base_path + 'data/type_%s/after_anomaly_detection/' % type_num\n",
    "\n",
    "    sum_filename = 'type%s_%s' % (type_num, type_num)\n",
    "    file_names_list = find_files(type_num_original_path)\n",
    "\n",
    "    if sum_flag:\n",
    "        print('Anomaly detection of sum file...')\n",
    "        file_names_list = [sum_filename]\n",
    "    else:\n",
    "        print('Anomaly detection of single file...')\n",
    "        try:\n",
    "            file_names_list.remove(sum_filename)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for file_name in file_names_list:\n",
    "        co_name, user_id = file_name.split('_')\n",
    "        print('-------' + co_name + '--------')\n",
    "        print('-------' + user_id + '--------')\n",
    "\n",
    "        # 导入行业x的数据\n",
    "        df = pd.read_csv(type_num_original_path + file_name + '.csv')\n",
    "\n",
    "        data = df.iloc[:, 1:].values\n",
    "        print('Any nan?', np.any(np.isnan(data)))\n",
    "        df = df.fillna(method='ffill')\n",
    "        data = df.iloc[:, 1:].values\n",
    "        print('Any nan?', np.any(np.isnan(data)))\n",
    "\n",
    "        if need_ad:\n",
    "            # 异常值分析 - 3σ原则\n",
    "#             data = three_sigma_alg(anomaly_detection_path, df, user_id, co_name)\n",
    "            data = smoothing(df)\n",
    "        else:\n",
    "            data = df['load']\n",
    "\n",
    "        # 保存csv文件\n",
    "        if not os.path.exists(type_num_after_anomaly_detection_path):\n",
    "            os.makedirs(type_num_after_anomaly_detection_path)\n",
    "        df['load'] = data\n",
    "        df.to_csv(type_num_after_anomaly_detection_path + '%s_%s.csv' % (co_name, user_id), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f968142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection of single file...\n",
      "-------南京第一农药集团有限公司(桠溪镇东风路8号)--------\n",
      "-------150991350--------\n",
      "Any nan? False\n",
      "Any nan? False\n",
      "-------南京先声东元制药有限公司--------\n",
      "-------930131545--------\n",
      "Any nan? False\n",
      "Any nan? False\n",
      "-------南京白敬宇制药有限责任公司--------\n",
      "-------332212524--------\n",
      "Any nan? False\n",
      "Any nan? False\n",
      "\n",
      "week: 1\n",
      "week: 2\n",
      "week: 3\n",
      "week: 4\n",
      "week: 5\n",
      "week: 6\n",
      "week: 7\n",
      "week: 8\n",
      "week: 9\n",
      "week: 10\n",
      "week: 11\n",
      "week: 12\n",
      "week: 13\n",
      "week: 14\n",
      "week: 15\n",
      "week: 16\n",
      "week: 17\n",
      "week: 18\n",
      "week: 19\n",
      "week: 20\n",
      "week: 21\n",
      "week: 22\n",
      "week: 1\n",
      "week: 2\n",
      "week: 3\n",
      "week: 4\n",
      "week: 5\n",
      "week: 6\n",
      "week: 7\n",
      "week: 8\n",
      "week: 9\n",
      "week: 10\n",
      "week: 11\n",
      "week: 12\n",
      "week: 13\n",
      "week: 14\n",
      "week: 15\n",
      "week: 16\n",
      "week: 17\n",
      "week: 18\n",
      "week: 19\n",
      "week: 20\n",
      "week: 21\n",
      "week: 22\n"
     ]
    }
   ],
   "source": [
    "base_path = '../../../Downloads/Thesis-temp/'\n",
    "type_num = 7\n",
    "anomaly_detection_path = base_path + 'output/img/type_%s/anomaly_detection/' % type_num\n",
    "if os.path.exists(anomaly_detection_path):\n",
    "    shutil.rmtree(anomaly_detection_path)\n",
    "os.makedirs(anomaly_detection_path)\n",
    "anomaly_detection(base_path, type_num, anomaly_detection_path, need_ad=True)\n",
    "day_range = 48\n",
    "week_range = 7\n",
    "daily_load_plotting(base_path, type_num, start=1, end=150, week_range=week_range, day_range=day_range,\n",
    "                    norm='standard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d2c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
